import sys
import os
import time
import argparse
import threading
import queue
import gc
import warnings
import tempfile  # ç”¨æ–¼è™•ç†æš«å­˜éŸ³æª”
import numpy as np
import sounddevice as sd
import soundfile as sf

# å¼•å…¥å¤–éƒ¨ä¾è³´
try:
    import pyrubberband as pyrb
    from opencc import OpenCC
    # å¦‚æœæ²’æœ‰å®‰è£ librosaï¼Œé€™è£¡å¯èƒ½éœ€è¦è™•ç†ï¼Œä½† pyrb é€šå¸¸ä¾è³´å®ƒ
    import librosa 
except ImportError as e:
    print(f"éŒ¯èª¤: ç¼ºå°‘å¿…è¦å¥—ä»¶ {e.name}ã€‚è«‹ç¢ºä¿å·²å®‰è£ pyrubberband, librosa å’Œ opencc-python-reimplemented")
    sys.exit(1)

# ==================== 1. ç’°å¢ƒåˆå§‹åŒ– (ä½¿ç”¨ runtime_setup) ====================
import runtime_setup

# åˆå§‹åŒ–ä¸¦å–å¾—è·¯å¾‘
env_paths = runtime_setup.initialize(__file__)
INDEX_TTS_DIR = env_paths["INDEX_TTS_DIR"]

# è¨­å®š Python Path
sys.path.append(INDEX_TTS_DIR)
sys.path.append(os.path.join(INDEX_TTS_DIR, "indextts"))

# å¿…é ˆåœ¨å°å…¥ torch ä¹‹å‰è¨­å®š,é¿å… DeepSpeed ç·¨è­¯æª¢æŸ¥
import torch

# IndexTTS æ¨¡çµ„å°å…¥ (å¿…é ˆåœ¨ sys.path è¨­å®šå¾Œ)
from indextts.infer_v2 import IndexTTS2
from indextts.infer import IndexTTS
from indextts.infer_streaming_patch import add_streaming_to_indextts

# ==================== 2. å…¨åŸŸè¨­å®šèˆ‡å·¥å…·å‡½æ•¸ ====================

# ç¹ç°¡è½‰æ›
cc = OpenCC('t2s')

def convert_to_simplified(text):
    return cc.convert(text)

def get_timestamp(start_time):
    """ç²å–ç›¸å°æ™‚é–“æˆ³è¨˜ï¼ˆç§’ï¼‰"""
    return time.time() - start_time

def check_cuda():
    """æª¢æŸ¥ä¸¦æ‰“å° CUDA ç‹€æ…‹"""
    print(f"\n{'='*20} ç¡¬é«”ç‹€æ…‹ {'='*20}")
    if torch.cuda.is_available():
        print(f"CUDA ç‰ˆæœ¬   : {torch.version.cuda}")
        print(f"GPU å‹è™Ÿ    : {torch.cuda.get_device_name(0)}")
        print(f"é¡¯å­˜ (ç¸½é‡) : {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
        torch.cuda.empty_cache()
    else:
        print("âš ï¸ CUDA ä¸å¯ç”¨, å°‡ä½¿ç”¨ CPU (é€Ÿåº¦æœƒå—å½±éŸ¿)")

# æ–‡å­—åˆ‡åˆ†é‚è¼¯
def split_text_smart(text, target_length=20, min_length=6):
    """å„ªåŒ–ç‰ˆåˆ‡åˆ†ï¼šå„ªå…ˆåœ¨æ¨™é»åˆ‡åˆ†"""
    punctuation = 'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€,.'
    max_length = int(target_length * 1.5)
    segments = []
    current_segment = ""
    
    for char in text:
        current_segment += char
        if len(current_segment) >= min_length and char in punctuation:
            clean_seg = current_segment.strip()
            if clean_seg: segments.append(clean_seg)
            current_segment = ""
        elif len(current_segment) >= max_length:
            clean_seg = current_segment.strip()
            if clean_seg: segments.append(clean_seg)
            current_segment = ""
            
    if current_segment.strip():
        segments.append(current_segment.strip())
        
    # äºŒæ¬¡æ¸…ç†
    return [seg.lstrip(punctuation).strip() for seg in segments if seg.lstrip(punctuation).strip()]

# ==================== [å„ªåŒ–ç§»æ¤] è®Šé€Ÿè™•ç†é‚è¼¯ ====================
def time_stretch_robust(audio_data, sample_rate, speed_factor, quality='speech'):
    """
    ç©©å¥çš„è®Šé€Ÿè™•ç† (æ•´åˆè‡ª prepare_speed_ref_final.py)
    """
    # å˜—è©¦ä½¿ç”¨ pyrubberband
    try:
        if quality == 'speech':
            # å„ªå…ˆå˜—è©¦èªéŸ³å„ªåŒ–åƒæ•¸ (é«˜æ¸…æ™°åº¦)
            try:
                # ä¿®æ­£å¾Œçš„åƒæ•¸å‚³éæ–¹å¼ï¼Œé¿å… TypeError
                return pyrb.time_stretch(
                    audio_data, 
                    sample_rate, 
                    speed_factor,
                    rbargs={'-c': 6} # Crispness 6 (High) é˜²æ­¢æ··éŸ¿
                )
            except Exception:
                # åƒæ•¸å¤±æ•—å‰‡é™ç´š
                pass
        
        # åŸºæœ¬æ¨¡å¼
        return pyrb.time_stretch(audio_data, sample_rate, speed_factor)
        
    except Exception:
        # å¦‚æœ pyrubberband å®Œå…¨å¤±æ•—ï¼Œå˜—è©¦ librosa
        # print("  âš ï¸ pyrubberband å¤±æ•—ï¼Œåˆ‡æ›è‡³ librosa (éŸ³è³ªå¯èƒ½è¼ƒå·®)")
        return librosa.effects.time_stretch(audio_data, rate=speed_factor)

# ==================== 3. æ’­æ”¾å™¨é‚è¼¯ (ç¨ç«‹åŸ·è¡Œç·’) ====================

class AudioPlayer(threading.Thread):
    def __init__(self, sample_rate, speed_factor=1.0):
        super().__init__(daemon=True)
        self.queue = queue.Queue()
        self.active = threading.Event()
        self.active.set()
        self.sample_rate = sample_rate
        self.speed_factor = speed_factor
        self.events = [] # è¨˜éŒ„æ’­æ”¾äº‹ä»¶
        self.start_ref_time = 0

    def set_start_time(self, start_time):
        self.start_ref_time = start_time

    def put_chunk(self, audio_data, duration, chunk_id):
        self.queue.put((audio_data, duration, chunk_id))

    def stop(self):
        self.queue.put(None) # çµæŸä¿¡è™Ÿ
        self.join()

    def run(self):
        chunk_idx = 0
        print(f"[Player] æ’­æ”¾åŸ·è¡Œç·’å•Ÿå‹• (æ¡æ¨£ç‡: {self.sample_rate}, æ’­æ”¾å€é€Ÿ: {self.speed_factor}x)")
        
        while self.active.is_set():
            try:
                item = self.queue.get(timeout=0.5)
                if item is None: break # æ”¶åˆ°çµæŸä¿¡è™Ÿ

                audio_normalized, original_duration, chunk_id = item
                chunk_idx += 1
                
                # è®Šé€Ÿè™•ç† (å¾Œè™•ç†/æ’­æ”¾åŠ é€Ÿ)
                if abs(self.speed_factor - 1.0) > 0.01:
                    try:
                        audio_play = time_stretch_robust(audio_normalized, self.sample_rate, self.speed_factor)
                    except Exception as e:
                        print(f"âš ï¸ æ’­æ”¾æ™‚è®Šé€Ÿå¤±æ•—: {e}")
                        audio_play = audio_normalized
                else:
                    audio_play = audio_normalized

                # è¨˜éŒ„é–‹å§‹
                play_start = get_timestamp(self.start_ref_time)
                self.events.append({'event': 'play_start', 'chunk': chunk_id, 'timestamp': play_start, 'duration': original_duration})
                
                # print(f"[ğŸ”Š Play] ç‰‡æ®µ {chunk_id} é–‹å§‹æ’­æ”¾")
                
                # æ’­æ”¾ (é˜»å¡ç›´åˆ°æ’­å®Œ)
                sd.play(audio_play, samplerate=self.sample_rate)
                sd.wait()

                # è¨˜éŒ„çµæŸ
                self.queue.task_done()
                
            except queue.Empty:
                continue
        print("[Player] æ’­æ”¾åŸ·è¡Œç·’çµæŸ")

# ==================== 4. ä¸»ç¨‹å¼é‚è¼¯ ====================

def main():
    # --- 0. å±è”½å¹²æ“¾è¨Šæ¯ ---
    warnings.filterwarnings("ignore", category=FutureWarning) 
    os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
    ref_audio_dir = os.path.join(INDEX_TTS_DIR, "examples")
    ref_audio_dist = {
        "voice_03.wav":  os.path.join(ref_audio_dir, "voice_03.wav"),
        "voice_06.wav":  os.path.join(ref_audio_dir, "voice_06.wav"),
        "voice_07.wav":  os.path.join(ref_audio_dir, "voice_07.wav"),
        "voice_11.wav":  os.path.join(ref_audio_dir, "voice_11.wav"),
        "é˜¿ç’‹.wav":  os.path.join(ref_audio_dir, "é˜¿ç’‹.wav"),
        "GY.wav":  os.path.join(ref_audio_dir, "GY.wav"),
        "DIDI.wav":  os.path.join(ref_audio_dir, "DIDI.wav"),
        "JADE.wav":  os.path.join(ref_audio_dir, "JADE.wav"),
        "Joneshong.wav":  os.path.join(ref_audio_dir, "Joneshong.wav"),
        "Sean.wav":  os.path.join(ref_audio_dir, "Sean.wav"),
    }
    # --- åƒæ•¸è§£æ ---
    parser = argparse.ArgumentParser(description="Index-TTS Streaming Test")
    parser.add_argument("--version", type=str, default="v2", choices=["v1", "v2"], help="æ¨¡å‹ç‰ˆæœ¬")
    parser.add_argument("--method", type=str, default="token", choices=["token", "word"], help="åˆ‡åˆ†æ–¹æ³• (v2 Only)")
    parser.add_argument("--model_dir", type=str, default=None, help="æ¨¡å‹è³‡æ–™å¤¾è·¯å¾‘")
    parser.add_argument("--ref_audio", type=str, default=ref_audio_dist["Joneshong.wav"], help="åƒè€ƒéŸ³é »è·¯å¾‘")
    parser.add_argument("--text", type=str, default=None, help="æ¸¬è©¦æ–‡æœ¬")
    parser.add_argument("--steps", type=int, default=5, help="æ“´æ•£æ¨¡å‹æ­¥æ•¸ (åƒ…åƒè€ƒ)")
    parser.add_argument("--warmup", action="store_true", help="æ˜¯å¦åŸ·è¡Œæ¨¡å‹é ç†±")
    
    # è®Šé€Ÿç›¸é—œåƒæ•¸ (ä¿®æ”¹éƒ¨åˆ†)
    parser.add_argument("--speed", type=float, default=1.0, 
                        help="[å¾Œè™•ç†] æ’­æ”¾åŠ é€Ÿå€ç‡ (ç”Ÿæˆå¾Œæ‰åŠ é€Ÿï¼Œé è¨­ 1.0)")
    
    parser.add_argument("--pre_speed_ref", type=float, default=1.0, 
                        help="[é è™•ç†] åƒè€ƒéŸ³æª”åŠ é€Ÿå€ç‡ (TTSç”Ÿæˆå‰å…ˆåŠ é€Ÿåƒè€ƒéŸ³æª”ï¼Œé è¨­ 1.0)")
    
    args = parser.parse_args()

    # --- æ–‡æœ¬è™•ç† ---
    default_text = (
        "åŠ‰ä½©çœŸåˆ†æï¼Œè¡Œæ”¿é™¢ã€Œé–‹æ°´é¾é ­ã€ï¼Œ9æœˆåˆæ–°é’å®‰é¬†ç¶ï¼ŒåŠå»¶é•·å°å…ˆè²·å¾Œè³£æ›å±‹æ—å‡ºå”®èˆŠå±‹çš„æœŸé™ï¼Œè§€æœ›çš„å¸‚å ´æ°›åœç¨æ¸›ï¼Œæˆ¿å¸‚äº¤æ˜“é‡å‡ºç¾å°å¹…æˆé•·ï¼Œ"
        "äº‹å¯¦ä¸Šï¼Œä»Šå¹´æˆ¿å¸‚çš„äº¤æ˜“çµæ§‹å·²å¾å»å¹´çš„åƒ¹é‡é½Šæšï¼Œåˆ°ä»Šå¹´çš„é‡ç¸®ã€åƒ¹æ ¼ç·©è·Œã€‚"
        "ç›®å‰æˆ¿åƒ¹çš„è·Œå¹…æ–¹é¢ï¼Œç›¸è¼ƒæ–¼å»å¹´é‚„æœ‰éå¸¸ä½å€‹ä½æ•¸çš„ä¸‹æ»‘ï¼Œé¡¯ç¤ºæˆ¿å¸‚è³£æ–¹å¯¦éš›ä¸Šæ²’æœ‰å‡ºè„«çš„å£“åŠ›ã€‚"
    )
    target_text = args.text if args.text else default_text
    text_simplified = convert_to_simplified(target_text)

    # --- é¡¯ç¤ºé…ç½® ---
    print(f"\n{'='*20} æ¸¬è©¦é…ç½® {'='*20}")
    print(f"ç‰ˆæœ¬: {args.version}")
    print(f"æ–¹æ³•: {args.method}")
    print(f"åƒè€ƒéŸ³æª”: {os.path.basename(args.ref_audio)}")
    print(f"--------------------")
    print(f"1. åƒè€ƒéŸ³æª”åŠ é€Ÿ (TTSæ¨¡ä»¿): {args.pre_speed_ref}x")
    print(f"2. æ’­æ”¾å¾Œè£½åŠ é€Ÿ (DSPè™•ç†): {args.speed}x")
    print(f"--------------------")
    
    check_cuda()

    # --- è®Šé€Ÿç­–ç•¥è™•ç† (æ ¸å¿ƒä¿®æ”¹) ---
    # Logic:
    # 1. actual_ref_audio_path: å¯¦éš›å‚³çµ¦ TTS çš„è·¯å¾‘ã€‚è‹¥ pre_speed_ref != 1.0ï¼Œå‰‡ç‚ºæš«å­˜æª”è·¯å¾‘ã€‚
    # 2. player_speed_factor: æ’­æ”¾å™¨çš„é€Ÿåº¦ï¼Œç›´æ¥ä½¿ç”¨ args.speedã€‚
    
    temp_file_obj = None     # ä¿å­˜ temp file ç‰©ä»¶
    actual_ref_audio_path = args.ref_audio
    
    # åŸ·è¡Œ [é è™•ç†] åƒè€ƒéŸ³æª”åŠ é€Ÿ
    if abs(args.pre_speed_ref - 1.0) > 0.01:
        print(f"\nâš¡ æ­£åœ¨åŸ·è¡Œåƒè€ƒéŸ³æª”é åŠ é€Ÿ (å€ç‡: {args.pre_speed_ref}x)...")
        try:
            # 1. è®€å–åŸå§‹åƒè€ƒéŸ³æª”
            y, sr = sf.read(args.ref_audio)
            if len(y.shape) > 1: y = np.mean(y, axis=1) # è½‰å–®è²é“
            
            # 2. è®Šé€Ÿè™•ç† (ä½¿ç”¨ robust æ–¹æ³•)
            y_fast = time_stretch_robust(y, sr, args.pre_speed_ref, quality='speech')
            
            # 3. å¯«å…¥æš«å­˜æª” (Windows å…¼å®¹å¯«æ³•: delete=False, æ‰‹å‹•åˆªé™¤)
            # delete=False æ˜¯ç‚ºäº†ç¢ºä¿åœ¨ close ä¹‹å¾Œï¼Œæª”æ¡ˆé‚„åœ¨ç£ç¢Ÿä¸Šä¾› TTS è®€å–
            tf = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
            sf.write(tf.name, y_fast, sr)
            tf.close() # é—œé–‰æª”æ¡ˆ handleï¼Œé‡‹æ”¾ lockï¼Œè®“ TTS å¯ä»¥è®€å–
            
            temp_file_obj = tf # ä¿å­˜å¼•ç”¨ä»¥ä¾¿å¾ŒçºŒåˆªé™¤
            actual_ref_audio_path = tf.name
            
            print(f"  âœ“ é åŠ é€Ÿå®Œæˆ")
            print(f"  âœ“ æš«å­˜åƒè€ƒéŸ³æª”è·¯å¾‘: {actual_ref_audio_path}")
            
        except Exception as e:
            print(f"âŒ é åŠ é€Ÿè™•ç†å¤±æ•—: {e}")
            # å¦‚æœå¤±æ•—ï¼Œå›é€€åˆ°åŸå§‹éŸ³æª”
            actual_ref_audio_path = args.ref_audio
            if temp_file_obj and os.path.exists(temp_file_obj.name):
                os.remove(temp_file_obj.name)
            temp_file_obj = None

    # --- è¼‰å…¥æ¨¡å‹ ---
    print("\n=== è¼‰å…¥æ¨¡å‹ä¸­... ===")
    start_load = time.time()
    
    tts_model = None
    sampling_rate = 22050 

    if args.version == "v2":
        model_dir = args.model_dir or os.path.join(INDEX_TTS_DIR, "checkpoints_v2")
        config_path = os.path.join(model_dir, "config.yaml")
        sampling_rate = 22050
        
        tts_model = IndexTTS2(
            cfg_path=config_path,
            model_dir=model_dir,
            use_fp16=True,
            use_cuda_kernel=False,
            use_deepspeed=False,
            use_accel=False,
            use_torch_compile=False
        )
    else: # v1
        model_dir = args.model_dir or os.path.join(INDEX_TTS_DIR, "checkpoints_v1.5")
        config_path = os.path.join(model_dir, "config.yaml")
        sampling_rate = 24000
        
        tts_model = IndexTTS(
            model_dir=model_dir,
            cfg_path=config_path,
            use_fp16=True,
            use_cuda_kernel=False
        )
        tts_model = add_streaming_to_indextts(tts_model)

    print(f"âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ (è€—æ™‚: {time.time() - start_load:.2f}s)")

    # ==================== æ¨¡å‹é ç†± ====================
    if args.warmup:
        print(f"\n{'='*20} ğŸ”¥ æ¨¡å‹é ç†± {'='*20}")
        print("æ­£åœ¨åŸ·è¡Œé ç†±...")
        warmup_start = time.time()
        warmup_text = "æ¸¬è©¦é ç†±ã€‚"
        try:
            if args.version == "v2":
                dummy_kwargs = {
                    "spk_audio_prompt": actual_ref_audio_path, # ä½¿ç”¨è™•ç†å¾Œçš„è·¯å¾‘
                    "text": convert_to_simplified(warmup_text),
                    "output_path": None,
                    "stream_return": True,
                    "interval_silence": 150,
                    "verbose": False,
                    "use_emo_text": False,
                    "emo_vector": None
                }
                if args.method == "token":
                    dummy_kwargs["max_text_tokens_per_segment"] = 68
                for _ in tts_model.infer(**dummy_kwargs): pass
            else:
                for _ in tts_model.infer_stream(actual_ref_audio_path, convert_to_simplified(warmup_text), verbose=False): pass
            
            if torch.cuda.is_available(): torch.cuda.synchronize()
            print(f"âœ… é ç†±å®Œæˆ (è€—æ™‚: {time.time() - warmup_start:.2f}s)")
        except Exception as e:
            print(f"âš ï¸ é ç†±éŒ¯èª¤: {e}")

    # --- æº–å‚™æ’­æ”¾å™¨ ---
    # args.speed ç”¨æ–¼å¾Œè™•ç† (DSP Time Stretch)
    player = AudioPlayer(sample_rate=sampling_rate, speed_factor=args.speed)
    player.start()

    # --- æº–å‚™ç”Ÿæˆ ---
    processing_queue = [] 
    if args.version == "v2" and args.method == "token":
        processing_queue.append((text_simplified, "full_text"))
    else:
        segments = split_text_smart(text_simplified)
        print(f"ğŸ“ æ‰‹å‹•åˆ‡åˆ†: å…± {len(segments)} æ®µ")
        for i, seg in enumerate(segments):
            processing_queue.append((seg, f"segment_{i+1}"))

    # --- é–‹å§‹ç”Ÿæˆè¿´åœˆ ---
    global_start_time = time.time()
    player.set_start_time(global_start_time)
    
    chunk_count = 0
    first_chunk_time = None
    generation_events = []
    speed_stats = [] 

    print(f"\n[ğŸš€ Start] é–‹å§‹ä¸²æµç”Ÿæˆ...")

    try:
        # ä½¿ç”¨ try...finally ç¢ºä¿æš«å­˜æª”è¢«åˆªé™¤
        try:
            for text_input, label in processing_queue:
                print(f"[ğŸ¬ Gen] æ­£åœ¨è™•ç†: {label} ({len(text_input)}å­—)")

                audio_generator = None
                
                if args.version == "v2":
                    kwargs = {
                        "spk_audio_prompt": actual_ref_audio_path, # ä½¿ç”¨æ­£ç¢ºçš„åƒè€ƒéŸ³æª”è·¯å¾‘
                        "text": text_input,
                        "output_path": None,
                        "stream_return": True,
                        "interval_silence": 150,
                        "verbose": False,
                        "use_emo_text": False,
                        "emo_vector": None
                    }
                    if args.method == "token":
                        kwargs["max_text_tokens_per_segment"] = 68
                    audio_generator = tts_model.infer(**kwargs)
                else:
                    audio_generator = tts_model.infer_stream(actual_ref_audio_path, text_input, verbose=False)

                t_last_chunk_finish = time.time()

                for audio_chunk in audio_generator:
                    t_now_abs = time.time()
                    t_now_rel = get_timestamp(global_start_time)
                    chunk_latency = t_now_abs - t_last_chunk_finish
                    t_last_chunk_finish = t_now_abs 
                    chunk_count += 1

                    if isinstance(audio_chunk, list):
                        audio_chunk = torch.cat(audio_chunk, dim=-1) if len(audio_chunk) > 0 else torch.zeros(1)
                    audio_np = audio_chunk.cpu().numpy().squeeze()
                    audio_normalized = audio_np.astype(np.float32) / 32767.0
                    duration = audio_np.shape[-1] / sampling_rate
                    
                    if chunk_latency > 0.01:
                        gen_rate = duration / chunk_latency
                        speed_stats.append(gen_rate)
                    
                    if duration < 0.05: continue 

                    if first_chunk_time is None:
                        first_chunk_time = t_now_rel
                        print(f"[âš¡ First Token] é¦–å€‹éŸ³è¨Šå·²ç”Ÿæˆ: {first_chunk_time:.2f}s")

                    generation_events.append({
                        'event': 'generate',
                        'chunk': chunk_count,
                        'timestamp': t_now_rel,
                        'duration': duration
                    })

                    player.put_chunk(audio_normalized, duration, chunk_count)
                    if duration > 0.1:
                        print(f"  -> [Queue] ç‰‡æ®µ {chunk_count} (éŸ³é•· {duration:.2f}s, è€—æ™‚ {chunk_latency:.2f}s, å€ç‡ {gen_rate:.2f}x)")
        except KeyboardInterrupt:
            print("\nâš ï¸ ä½¿ç”¨è€…ä¸­æ–·")
        except Exception as e:
            print(f"\nâŒ ç”Ÿæˆéç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()

    finally:
        # æ¸…ç†æš«å­˜æª” (ç„¡è«–æ˜¯å¦ç™¼ç”ŸéŒ¯èª¤)
        if temp_file_obj:
            try:
                # ç¢ºä¿é—œé–‰
                if not temp_file_obj.closed:
                    temp_file_obj.close()
                
                # åˆªé™¤å¯¦é«”æª”æ¡ˆ
                if os.path.exists(temp_file_obj.name):
                    os.remove(temp_file_obj.name)
                    print(f"\nğŸ—‘ï¸ å·²æ¸…ç†æš«å­˜åƒè€ƒéŸ³æª”: {temp_file_obj.name}")
            except Exception as e:
                print(f"âš ï¸ æ¸…ç†æš«å­˜æª”æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    total_gen_time = get_timestamp(global_start_time)
    print(f"\n[ğŸ Finish] æ‰€æœ‰ç”Ÿæˆä»»å‹™å®Œæˆ (ç¸½è€—æ™‚: {total_gen_time:.2f}s)")
    
    player.stop()

    # ==================== 5. ç¶œåˆçµ±è¨ˆå ±å‘Š ====================
    print(f"\n{'='*80}")
    print(f"ğŸ“Š ç¶œåˆçµ±è¨ˆå ±å‘Š")
    print(f"{'='*80}")

    # --- A. åƒæ•¸é…ç½® ---
    print(f"ğŸ”§ åŸ·è¡Œåƒæ•¸ (Arguments):")
    for k, v in vars(args).items():
        print(f"  â€¢ {k:<12} : {v}")
    
    # print(f"ğŸ”§ åŸ·è¡Œåƒæ•¸:")
    # print(f"  â€¢ åƒè€ƒéŸ³æª”   : {os.path.basename(args.ref_audio)}")
    # print(f"  â€¢ é è™•ç†åŠ é€Ÿ : {args.pre_speed_ref}x {'(ä½¿ç”¨æš«å­˜æª”)' if args.pre_speed_ref != 1.0 else '(ç„¡)'}")
    # print(f"  â€¢ å¾Œè™•ç†åŠ é€Ÿ : {args.speed}x {'(æ’­æ”¾æ™‚ DSP è™•ç†)' if args.speed != 1.0 else '(ç„¡)'}")
    # --- B. åƒè€ƒéŸ³è¨Šåˆ†æ ---
    print(f"\nğŸµ åƒè€ƒéŸ³è¨Šè³‡è¨Š (Ref Audio):")
    if os.path.exists(args.ref_audio):
        try:
            file_size_bytes = os.path.getsize(args.ref_audio)
            file_size_mb = file_size_bytes / (1024 * 1024)
            sf_info = sf.info(args.ref_audio)
            duration = sf_info.duration
            samplerate = sf_info.samplerate
            subtype = sf_info.subtype
            bitrate_kbps = (file_size_bytes * 8) / duration / 1000 if duration > 0 else 0
            
            print(f"  â€¢ æª”å (File)    : {os.path.basename(args.ref_audio)}")
            print(f"  â€¢ å¤§å° (Size)    : {file_size_mb:.2f} MB")
            print(f"  â€¢ ç§’æ•¸ (Length)  : {duration:.2f} s")
            print(f"  â€¢ æ ¼å¼ (Format)  : {sf_info.format} ({subtype})")
            print(f"  â€¢ æ¡æ¨£ (Rate)    : {samplerate} Hz")
            print(f"  â€¢ ç¢¼ç‡ (Bitrate) : {bitrate_kbps:.0f} kbps")
        except Exception as e:
            print(f"  âš ï¸ ç„¡æ³•è®€å–éŸ³è¨Šè³‡è¨Š: {e}")
    else:
        print(f"  âš ï¸ æ‰¾ä¸åˆ°æª”æ¡ˆ: {args.ref_audio}")

    
    print(f"\nğŸš€ æ•ˆèƒ½æŒ‡æ¨™:")
    print(f"  â€¢ é¦–æ¬¡éŸ¿æ‡‰   : {first_chunk_time if first_chunk_time else 'N/A'}")
    print(f"  â€¢ ç¸½è€—æ™‚     : {total_gen_time:.2f} s")
    
    # [ä¿®æ­£] é¡¯ç¤ºç”Ÿæˆå€ç‡ (Audio Generation Rate)
    if speed_stats:
        avg_rate = np.mean(speed_stats)
        max_rate = np.max(speed_stats)
        min_rate = np.min(speed_stats)
        avg_rate = np.mean(speed_stats)
        print(f"  â€¢ ç”Ÿæˆå€ç‡ (Audio/Process Speed):")
        print(f"    (æ•¸å€¼ > 1.0 ä»£è¡¨ç”Ÿæˆé€Ÿåº¦æ¯”æ’­æ”¾é€Ÿåº¦å¿«)")
        print(f"      Avg : {avg_rate:.2f} x")
        print(f"      Max : {max_rate:.2f} x")
        print(f"      Min : {min_rate:.2f} x")
        
        # ä¼°ç®—æ•´é«” RTF
        total_audio_len = sum(e['duration'] for e in generation_events)
        overall_rtf = total_gen_time / total_audio_len if total_audio_len > 0 else 0
        print(f"  â€¢ æ•´é«”å¯¦æ™‚ç‡ (RTF): {overall_rtf:.3f} (è¶Šä½è¶Šå¥½)")
    else:
        print(f"  â€¢ ç”Ÿæˆå€ç‡: N/A")

    # ä¸¦è¡Œæ•ˆç‡
    overlap_count = 0
    playback_events = player.events
    if len(generation_events) > 1 and len(playback_events) > 0:
        for gen_event in generation_events[1:]:
            g_time = gen_event['timestamp']
            for play_event in playback_events:
                p_start = play_event['timestamp']
                p_end = p_start + (play_event['duration'] / args.speed)
                if p_start <= g_time <= p_end:
                    overlap_count += 1
                    break
        efficiency = (overlap_count / max(chunk_count - 1, 1)) * 100
        print(f"  â€¢ ä¸¦è¡Œæ•ˆç‡ (Parallel): {efficiency:.1f}% ({overlap_count}/{chunk_count-1} chunks overlapped)")
    
    print(f"{'='*80}\n")
    print("Done.")

if __name__ == "__main__":
    main()